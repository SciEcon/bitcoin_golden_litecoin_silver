{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SciEcon/bitcoin_golden_litecoin_silver/blob/main/UTXO_Automatic_Updater.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOKcNgBvwTEF"
      },
      "source": [
        "#Instructions:\n",
        "\n",
        "Before you run the program, please\n",
        "\n",
        "1. Add shortcut for the shared **UTXO folder** as a copy to your own google drive \n",
        "2. Make a copy of the Colab Notebook shared by your collaborator who made the last updates\n",
        "3. Change variables **currency** and **\"currency_brief\"** to currency of your choice. \n",
        "\n",
        "> The choice set = {'litecoin', 'dogecoin', 'dash', 'zcash', 'bitcoin_cash'}\n",
        "\n",
        "> The choice_brief set = {'ltc', 'dgc', 'dash', 'zec', 'bch'}\n",
        "\n",
        "4. Change the variable **last_update** and (update) **end** to the date of your choice\n",
        "\n",
        "After you run the program, please \n",
        "\n",
        "1.   Update the lastest update date below.\n",
        "2.   Share the latest Colab Notebook with Collaborators\n",
        "3.   Share the updated UTXO folder with Collaborators\n",
        "\n",
        "Up to now, \n",
        "\n",
        "*   Bitcoin (btc) is updated until 2021-02-10.\n",
        "*   litecoin (ltc) is updated until 2020-12-31.\n",
        "*   dogecoin (dgc) is updated until 2020-12-31.\n",
        "*   dash (dash) is updated until 2021-02-20.\n",
        "*   zcash (zec) is updated until 2020-12-31.\n",
        "*   bitcoin_cash (bch) is updated until 2020-12-31.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5BBxnuqVx03"
      },
      "source": [
        "# Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN5ZNqf4UgTn"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import decimal\n",
        "from datetime import datetime, date, timedelta, timezone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Foxw5lL-ZqCP"
      },
      "source": [
        "Please change the input listed in this code box."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Txuu9OhqejbE"
      },
      "outputs": [],
      "source": [
        "currency = \"litecoin\" #the name of the altcoin\n",
        "currency_brief = \"ltc\"\n",
        "last_update = date(2022,5,20)\n",
        "start = last_update + timedelta(days=1)\n",
        "end = date(2022,5,31)\n",
        "\n",
        "PROJECT_ID = 'sonic-glazing-354409'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3FUxcgJVi1N",
        "outputId": "379b88e8-3862-4935-b21d-410034c4e23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "#Connect to Google Cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7NvYDgcVk7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69ae3c0-f1db-4f33-a075-d918f2ce67b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "#Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Authenticated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n99kwqBV7vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17ea4c98-0155-4a4b-93c3-ec2d412d48ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "litecoin_UTXO\n"
          ]
        }
      ],
      "source": [
        "#Connect to Google BigQuery\n",
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=PROJECT_ID, location='US')\n",
        "dataset_ref = client.dataset(currency+'_UTXO', project=PROJECT_ID)\n",
        "dataset = client.get_dataset(dataset_ref)\n",
        "tables = list(client.list_tables(dataset))\n",
        "\n",
        "# Print names of all tables in the dataset\n",
        "for table in tables:  \n",
        "  print(table.table_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bVwfAJHaEfx"
      },
      "source": [
        "# Query the latest data in BigQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhwe8Oh1Vv7w"
      },
      "source": [
        "## Creating a Table for variables of interest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tFz0Q1cVyR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98950d7c-a2a8-4e8c-aa59-1c5a7621402e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query results loaded to the table sonic-glazing-354409.litecoin_UTXO.joint_all\n"
          ]
        }
      ],
      "source": [
        "#Create joint_all\n",
        "\n",
        "table_id_inputs = PROJECT_ID + \".\" + currency + \"_UTXO.joint_all\"\n",
        "job_config = bigquery.QueryJobConfig(destination=table_id_inputs)\n",
        "job_config.write_disposition = \"WRITE_TRUNCATE\"\n",
        "\n",
        "sql = \"\"\"\n",
        "  SELECT\n",
        "    (outputs.value/POW(10,8)) AS UTXO,  \n",
        "    outputs.block_timestamp,\n",
        "    inputs.block_timestamp AS spent_block_timestamp,\n",
        "    #FORMAT_TIMESTAMP(\"%Y-%m-%d\", block_timestamp) AS block_date,\n",
        "    #FORMAT_TIMESTAMP(\"%Y-%m-%d\", spent_block_timestamp) AS spent_block_date,\n",
        "  FROM \n",
        "    `bigquery-public-data.crypto_\"\"\" + currency + \"\"\".outputs` AS outputs\n",
        "  LEFT JOIN \n",
        "    `bigquery-public-data.crypto_\"\"\" + currency + \"\"\".inputs` AS inputs\n",
        "  ON outputs.transaction_hash=inputs.spent_transaction_hash  \n",
        "  AND outputs.index = inputs.spent_output_index\n",
        "\"\"\"\n",
        "\n",
        "# Start the query, passing in the extra configuration.\n",
        "query_job_inputs = client.query(sql, job_config=job_config)  # Make an API request.\n",
        "query_job_inputs.result()  # Wait for the job to complete.\n",
        "\n",
        "print(\"Query results loaded to the table {}\".format(table_id_inputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hog7UNQX3TEM"
      },
      "source": [
        "## Create partitioned tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPtoUbqf3Ssv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf50f58-4e91-49d4-bb13-9bcced388a0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query results loaded to the table\n"
          ]
        }
      ],
      "source": [
        "#Partition Table by born date for data after 2012\n",
        "\n",
        "job_config = bigquery.QueryJobConfig()\n",
        "sql = \"\"\"\n",
        "  CREATE OR REPLACE TABLE\n",
        "    `\"\"\" + PROJECT_ID + \".\" + currency + \"\"\"_UTXO.joint_all_partitionedbyborn14`\n",
        "  PARTITION BY\n",
        "    DATE(block_timestamp) \n",
        "    OPTIONS(partition_expiration_days= 5000, \n",
        "    require_partition_filter=true) AS\n",
        "\n",
        "  SELECT\n",
        "    *\n",
        "  FROM\n",
        "    `\"\"\" + PROJECT_ID + \".\" + currency + \"\"\"_UTXO.joint_all`\n",
        "  WHERE\n",
        "    block_timestamp > TIMESTAMP('2014-01-01 00:00:00+00')\n",
        "\"\"\"\n",
        "\n",
        "# Start the query, passing in the extra configuration.\n",
        "query_job_inputs = client.query(sql, job_config=job_config)  # Make an API request.\n",
        "query_job_inputs.result()  # Wait for the job to complete.\n",
        "\n",
        "print(\"Query results loaded to the table\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udq-ra9y3e6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5248a85b-7a75-47e8-87c5-8085a4efb8a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query results loaded to the table\n"
          ]
        }
      ],
      "source": [
        "#Partition by death date for data after 2012\n",
        "\n",
        "job_config = bigquery.QueryJobConfig()\n",
        "\n",
        "sql = \"\"\"\n",
        "  CREATE OR REPLACE TABLE\n",
        "    `sonic-glazing-354409.\"\"\" + currency + \"\"\"_UTXO.joint_all_partitionedbydeath14`\n",
        "  PARTITION BY\n",
        "    DATE(spent_block_timestamp) \n",
        "  OPTIONS(partition_expiration_days= 5000, \n",
        "    require_partition_filter=true) AS\n",
        "  SELECT\n",
        "    *\n",
        "  FROM\n",
        "    `sonic-glazing-354409.\"\"\" + currency + \"\"\"_UTXO.joint_all`\n",
        "  WHERE\n",
        "    (spent_block_timestamp > TIMESTAMP('2014-01-01 00:00:00+00')\n",
        "    OR \n",
        "    spent_block_timestamp IS NULL)\n",
        "\"\"\"\n",
        "\n",
        "# Start the query, passing in the extra configuration.\n",
        "query_job_inputs = client.query(sql, job_config=job_config)  # Make an API request.\n",
        "query_job_inputs.result()  # Wait for the job to complete.\n",
        "\n",
        "print(\"Query results loaded to the table\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkhi4SjO9Yoj"
      },
      "source": [
        "# Process the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4qrxW8Y5p9v"
      },
      "source": [
        "## Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEzTYHCp3pe7"
      },
      "outputs": [],
      "source": [
        "def cal(x):\n",
        "    t=np.sign(x-0.999)+np.sign(x-29.999)+np.sign(x-90.999)+np.sign(x-181.999)+np.sign(x-364.999)+np.sign(x-365*2+0.001)+np.sign(x-365*3+0.001)+np.sign(x-365*4+0.001)+np.sign(x-365*5+0.001)+np.sign(x-365*10+0.001)+1\n",
        "    return t\n",
        "\n",
        "def Task1_born(data):\n",
        "    newborn = data['UTXO'].sum()\n",
        "    return(newborn)\n",
        "\n",
        "#Partitioning By Death Date\n",
        "def Task1_dead(data):\n",
        "    dead = data['UTXO'].sum()\n",
        "    return(dead)\n",
        "\n",
        "def Task2(data):\n",
        "    #data['Life_Length'] = data['spent_block_timestamp']- data['block_timestamp']\n",
        "    #data['Life_Length'] = data['Life_Length'].map(lambda x:x.days).apply(float)\n",
        "    sumUTXO = data['UTXO'].sum()\n",
        "    sumLength = (data['UTXO']*data['Life_Length']).sum()\n",
        "    if sumUTXO == 0:\n",
        "        WALE = 0.0\n",
        "    else:\n",
        "        WALE = sumLength/sumUTXO\n",
        "    return(WALE)\n",
        "def Task3(data):\n",
        "    data['Life_Length'] = data['spent_block_timestamp']- data['block_timestamp']\n",
        "    data['Life_Length'] = data['Life_Length'].map(lambda x:x.days).apply(float)\n",
        "    data['categorical'] = cal(data['Life_Length'])\n",
        "    categories = [-9, -7, -5, -3, -1, 1, 3, 5, 7, 9, 11]\n",
        "    result=pd.DataFrame(np.zeros((1, 11)), columns=categories)\n",
        "    for i in categories:  \n",
        "        result.loc[:,i] = data[data['categorical']==i]['UTXO'].sum()  \n",
        "    return result\n",
        "\n",
        "def Task4(data, date):  \n",
        "    categories = [-9, -7, -5, -3, -1, 1, 3, 5, 7, 9, 11]\n",
        "    result=pd.DataFrame(np.zeros((1, 11)), columns=categories)\n",
        "    if len(data)!= 0:\n",
        "      data['Age'] = data['block_timestamp'].apply(lambda x: (date-x).days)\n",
        "      data['categorical'] = cal(data['Age'])\n",
        "      for i in categories: \n",
        "        result.loc[:,i] = data[data['categorical']==i]['UTXO'].sum()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxBbfG-9XS0n"
      },
      "outputs": [],
      "source": [
        "def STXOprogram(start, end):\n",
        "  duration=pd.date_range(start=start, end=end)\n",
        "  days = np.size(duration)\n",
        "  categories = [-9, -7, -5, -3, -1, 1, 3, 5, 7, 9, 11]\n",
        "  Result=pd.DataFrame(np.zeros((days, 11)), columns=categories)\n",
        "  Result['date'] = duration\n",
        "\n",
        "  for i in range(0, days):\n",
        "    try:\n",
        "      start_date = start + timedelta(days=i)\n",
        "      end_date = start_date + timedelta(days=1)\n",
        "    \n",
        "  #Partitioning by Dead Date\n",
        "      query2 = \"\"\"\n",
        "          SELECT \n",
        "            *\n",
        "          FROM \n",
        "             `\"\"\" + PROJECT_ID + \".\" + currency + \"\"\"_UTXO.joint_all_partitionedbydeath14`\n",
        "          WHERE\n",
        "            spent_block_timestamp >= TIMESTAMP('\"\"\" + str(start_date) + \"\"\" 00:00:00+00')\n",
        "          AND \n",
        "            spent_block_timestamp < TIMESTAMP('\"\"\" + str(end_date) + \"\"\" 00:00:00+00')\"\"\"\n",
        "      query_job2 = client.query(query2)\n",
        "    # Make an API request  to run the query and return a pandas DataFrame\n",
        "      data2 = query_job2.to_dataframe()  \n",
        "    \n",
        "    #Work on Task3\n",
        "      Result.iloc[i,0:11]=list(Task3(data2).iloc[0])\n",
        "    \n",
        "  #Partitioning by Born Date\n",
        "      query1 = \"\"\"\n",
        "          SELECT \n",
        "            CAST(UTXO AS FLOAT64) AS UTXO,\n",
        "            CAST(block_timestamp AS STRING) AS block_timestamp,\n",
        "            CAST(spent_block_timestamp AS STRING) AS spent_block_timestamp\n",
        "          FROM \n",
        "            `nomadic-pipe-295915.bitcoin_UTXO.joint_all_partitionedbyborn14`\n",
        "          WHERE\n",
        "            block_timestamp >= TIMESTAMP('\"\"\" + str(start_date) + \"\"\" 00:00:00+00')\n",
        "          AND \n",
        "            block_timestamp < TIMESTAMP('\"\"\" + str(end_date) + \"\"\" 00:00:00+00')\"\"\"\n",
        "      query_job1 = client.query(query1)\n",
        "    # Make an API request  to run the query and return a pandas DataFrame\n",
        "      data1 = query_job1.to_dataframe()\n",
        "    \n",
        "    #Work on Task 1 and Task 2\n",
        "      Result.loc[i,'newborn'] = Task1_born(data1)\n",
        "      Result.loc[i,'dead'] = Task1_dead(data2)\n",
        "      Result.loc[i,'WALE'] = Task2(data2)\n",
        "      Result.columns = ['-9', '-7', '-5', '-3', '-1', '1', '3', '5', '7', '9', '11', 'date', 'newborn', 'dead', 'WALE']\n",
        "    except:\n",
        "      print(start_date)\n",
        "  return Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB4oynVzYl07"
      },
      "outputs": [],
      "source": [
        "def UTXOprogram(start, end):\n",
        "  duration=pd.date_range(start=start, end=end)\n",
        "  days = np.size(duration)\n",
        "  categories = [-9, -7, -5, -3, -1, 1, 3, 5, 7, 9, 11]\n",
        "  Dist_Alive=pd.DataFrame(np.zeros((days, 11)), columns=categories)\n",
        "  Dist_Alive['date'] = duration\n",
        "  start_date=start+timedelta(days=1) \n",
        "  end_date =end+timedelta(days=1) \n",
        "  # note the trick below, we only keep data whose block_timestamp<end_date, and spent_block_timestamp>start_date\n",
        "  # must be from joint_all\n",
        "  query = \"\"\"\n",
        "      SELECT \n",
        "          CAST(UTXO AS FLOAT64) AS UTXO,\n",
        "          CAST(block_timestamp AS STRING) AS block_timestamp,\n",
        "          CAST(spent_block_timestamp AS STRING) AS spent_block_timestamp\n",
        "      FROM \n",
        "         `\"\"\" + PROJECT_ID + \".\" + currency + \"\"\"_UTXO.joint_all`\n",
        "      WHERE\n",
        "        block_timestamp < TIMESTAMP('\"\"\" + str(end_date) + \"\"\" 00:00:00+00')\n",
        "      AND \n",
        "        (spent_block_timestamp >= TIMESTAMP('\"\"\" + str(start_date) + \"\"\" 00:00:00+00')\n",
        "        OR\n",
        "        spent_block_timestamp IS NULL)\n",
        "     \"\"\"\n",
        "  query_job = client.query(query)\n",
        "\n",
        "# Make an API request  to run the query and return a pandas DataFrame\n",
        "  data = query_job.to_dataframe()\n",
        "  data['block_timestamp'] = pd.to_datetime(data['block_timestamp'], format='%Y-%m-%d')\n",
        "  data['spent_block_timestamp'] = pd.to_datetime(data['spent_block_timestamp'].fillna(pd.NaT), format='%Y-%m-%d')\n",
        "  for j in range(0, days):\n",
        "    working_date = pd.to_datetime(start_date + timedelta(days=j), utc=True)   \n",
        "    working_data = data.loc[((data.block_timestamp<working_date) & ((pd.isna(data.spent_block_timestamp) | (data.spent_block_timestamp>=working_date))))].copy()\n",
        "    Dist_Alive.iloc[j,0:11] = list(Task4(working_data, working_date).iloc[0])\n",
        "\n",
        "  return Dist_Alive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGHGy_L0nbe-"
      },
      "outputs": [],
      "source": [
        "def UTXOprogram1(start, end):\n",
        "  duration=pd.date_range(start=start, end=end)\n",
        "  days = np.size(duration)\n",
        "  categories = [-9, -7, -5, -3, -1, 1, 3, 5, 7, 9, 11]\n",
        "  Dist_Alive=pd.DataFrame(np.zeros((days, 11)), columns=categories)\n",
        "  Dist_Alive['date'] = duration\n",
        "  start_date=start+timedelta(days=1) \n",
        "  end_date =end+timedelta(days=1) \n",
        "  # note the trick below, we only keep data whose block_timestamp<end_date, and spent_block_timestamp>start_date\n",
        "  #must be from joint_all\n",
        "  query = \"\"\"\n",
        "      SELECT \n",
        "        *\n",
        "      FROM \n",
        "        `\"\"\" + PROJECT_ID + \".\" + currency + \"\"\"_UTXO.joint_all`\n",
        "      WHERE\n",
        "        block_timestamp < TIMESTAMP('\"\"\" + str(end_date) + \"\"\" 00:00:00+00')\n",
        "      AND \n",
        "        spent_block_timestamp >= TIMESTAMP('\"\"\" + str(start_date) + \"\"\" 00:00:00+00')\n",
        "     \"\"\"\n",
        "  query_job = client.query(query)\n",
        "\n",
        "# Make an API request  to run the query and return a pandas DataFrame\n",
        "  data = query_job.to_dataframe()\n",
        "  data['block_timestamp'] = pd.to_datetime(data['block_timestamp'], format='%Y-%m-%d')\n",
        "  data['spent_block_timestamp'] = pd.to_datetime(data['spent_block_timestamp'].fillna(pd.NaT), format='%Y-%m-%d')\n",
        "  for j in range(0, days):\n",
        "    working_date = pd.to_datetime(start_date + timedelta(days=j), utc=True)   \n",
        "    working_data = data.loc[((data.block_timestamp<working_date) & ((pd.isna(data.spent_block_timestamp) | (data.spent_block_timestamp>=working_date))))].copy()\n",
        "    Dist_Alive.iloc[j,0:11] = list(Task4(working_data, working_date).iloc[0])\n",
        "\n",
        "  return Dist_Alive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6YEbI2ni1-e"
      },
      "outputs": [],
      "source": [
        "def UTXOprogram2(start, end):\n",
        "  duration=pd.date_range(start=start, end=end)\n",
        "  days = np.size(duration)\n",
        "  categories = [-9, -7, -5, -3, -1, 1, 3, 5, 7, 9, 11]\n",
        "  Dist_Alive=pd.DataFrame(np.zeros((days, 11)), columns=categories)\n",
        "  Dist_Alive['date'] = duration\n",
        "  start_date=start+timedelta(days=1) \n",
        "  end_date =end+timedelta(days=1) \n",
        "  # note the trick below, we only keep data whose block_timestamp<end_date, and spent_block_timestamp>start_date\n",
        "  #must be from joint_all\n",
        "  query = \"\"\"\n",
        "      SELECT \n",
        "        *\n",
        "      FROM \n",
        "        `\"\"\" + PROJECT_ID + \".\" + currency + \"\"\"_UTXO.joint_all`\n",
        "      WHERE\n",
        "        block_timestamp < TIMESTAMP('2018-12-31 00:00:00+00')\n",
        "      AND \n",
        "        spent_block_timestamp IS NULL\n",
        "     \"\"\"\n",
        "  query_job = client.query(query)\n",
        "\n",
        "# Make an API request  to run the query and return a pandas DataFrame\n",
        "  data = query_job.to_dataframe()\n",
        "  data['block_timestamp'] = pd.to_datetime(data['block_timestamp'], format='%Y-%m-%d')\n",
        "  data['spent_block_timestamp'] = pd.to_datetime(data['spent_block_timestamp'], format='%Y-%m-%d')\n",
        "  for j in range(0, days):\n",
        "    working_date = pd.to_datetime(start_date + timedelta(days=j), utc=True)   \n",
        "    working_data = data.loc[(data.block_timestamp<working_date)].copy()\n",
        "    Dist_Alive.iloc[j,0:11] = list(Task4(working_data, working_date).iloc[0])\n",
        "\n",
        "  return Dist_Alive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jBu6s-AE4CX"
      },
      "outputs": [],
      "source": [
        "def UTXOprogram3(start, end):\n",
        "  duration=pd.date_range(start=start, end=end)\n",
        "  days = np.size(duration)\n",
        "  categories = [-9, -7, -5, -3, -1, 1, 3, 5, 7, 9, 11]\n",
        "  Dist_Alive=pd.DataFrame(np.zeros((days, 11)), columns=categories)\n",
        "  Dist_Alive['date'] = duration\n",
        "  start_date=start+timedelta(days=1) \n",
        "  end_date =end+timedelta(days=1) \n",
        "  # note the trick below, we only keep data whose block_timestamp<end_date, and spent_block_timestamp>start_date\n",
        "  #must be from joint_all\n",
        "  query = \"\"\"\n",
        "      SELECT \n",
        "        *\n",
        "      FROM \n",
        "        `\"\"\" + PROJECT_ID + \".\" + currency + \"\"\"_UTXO.joint_all`\n",
        "      WHERE\n",
        "        block_timestamp < TIMESTAMP('\"\"\" + str(end_date) + \"\"\" 00:00:00+00')\n",
        "      AND\n",
        "        block_timestamp > TIMESTAMP('2018-12-31 00:00:00+00')\n",
        "      AND \n",
        "        spent_block_timestamp IS NULL\n",
        "     \"\"\"\n",
        "  query_job = client.query(query)\n",
        "\n",
        "# Make an API request  to run the query and return a pandas DataFrame\n",
        "  data = query_job.to_dataframe()\n",
        "  data['block_timestamp'] = pd.to_datetime(data['block_timestamp'], format='%Y-%m-%d')\n",
        "  data['spent_block_timestamp'] = pd.to_datetime(data['spent_block_timestamp'], format='%Y-%m-%d')\n",
        "  for j in range(0, days):\n",
        "    working_date = pd.to_datetime(start_date + timedelta(days=j), utc=True)   \n",
        "    working_data = data.loc[(data.block_timestamp<working_date)].copy()\n",
        "    Dist_Alive.iloc[j,0:11] = list(Task4(working_data, working_date).iloc[0])\n",
        "\n",
        "  return Dist_Alive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_r0juK9_FcR"
      },
      "source": [
        "## STXO Program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DMrww7k_HWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de861de-4da1-4f15-fc0a-495b8e9c9b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-21\n",
            "2022-05-22\n",
            "2022-05-23\n",
            "2022-05-24\n",
            "2022-05-25\n",
            "2022-05-26\n",
            "2022-05-27\n",
            "2022-05-28\n",
            "2022-05-29\n",
            "2022-05-30\n",
            "2022-05-31\n"
          ]
        }
      ],
      "source": [
        "STXOresult = STXOprogram(start, end)\n",
        "\n",
        "oldaddress = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultSTXO' +str(last_update)+ '.csv'\n",
        "oldSTXOresult = pd.read_csv(oldaddress)\n",
        "oldSTXOresult = oldSTXOresult.drop(['Unnamed: 0'], axis = 1)\n",
        "newSTXOresult = oldSTXOresult.append(STXOresult)\n",
        "newaddress = '/content/drive/My Drive/UTXO/' +currency+ \"/\" + currency + 'ResultSTXO' +str(end)+ '.csv'\n",
        "newSTXOresult.to_csv(newaddress)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJKx4FFyWZlG"
      },
      "source": [
        "## UTXO Program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwRxsSKmbDAj"
      },
      "outputs": [],
      "source": [
        "UTXOresult = UTXOprogram(start, end)\n",
        "\n",
        "oldaddress = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultUTXO' +str(last_update)+ '.csv'\n",
        "oldUTXOresult = pd.read_csv(oldaddress)\n",
        "oldUTXOresult = oldUTXOresult.drop(['Unnamed: 0'], axis = 1)\n",
        "UTXOresult.columns = ['-9', '-7', '-5', '-3', '-1', '1', '3', '5', '7', '9', '11', 'date']\n",
        "UTXOresult = UTXOresult[['date', '-9', '-7', '-5', '-3', '-1', '1', '3', '5', '7', '9', '11']]\n",
        "newUTXOresult = oldUTXOresult.append(UTXOresult)\n",
        "newUTXOresult = newUTXOresult.reset_index(drop = True)\n",
        "duration=pd.date_range(start= end-timedelta(days=len(newUTXOresult)-1), end=end)\n",
        "newUTXOresult['date'] = duration\n",
        "newaddress = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultUTXO' +str(end)+ '.csv'\n",
        "newUTXOresult.to_csv(newaddress)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFmozDdVLVkf"
      },
      "source": [
        "### For Bitcoin and Bitcoin Cash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cer5krGjLbmj"
      },
      "source": [
        "The data of Bitcoin and Bitcoin Cash might exceed the limit of computer RAM. In this case, we query the data in several separate parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HglYE0qMc7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "82d1a15e-f260-461d-c08f-06f90964afca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-2054808dc090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mUTXOresult1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUTXOprogram1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnewaddress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/UTXO/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrency\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrency\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'ResultUTXO1'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mUTXOresult1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewaddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-e92dbde5ed47>\u001b[0m in \u001b[0;36mUTXOprogram1\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Make an API request  to run the query and return a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'block_timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'block_timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spent_block_timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spent_block_timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type)\u001b[0m\n\u001b[1;32m   3106\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3107\u001b[0m             \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3108\u001b[0;31m             \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3109\u001b[0m         )\n\u001b[1;32m   3110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m         for frame in self._to_dataframe_iterable(\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m         ):\n\u001b[1;32m   1584\u001b[0m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36m_to_page_iterable\u001b[0;34m(self, bqstorage_download, tabledata_list_download, bqstorage_client)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             )\n\u001b[1;32m   1378\u001b[0m         )\n\u001b[0;32m-> 1379\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtabledata_list_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/_pandas_helpers.py\u001b[0m in \u001b[0;36mdownload_dataframe_tabledata_list\u001b[0;34m(pages, schema, dtypes)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0m_tabledata_list_page_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/_pandas_helpers.py\u001b[0m in \u001b[0;36m_tabledata_list_page_to_dataframe\u001b[0;34m(page, column_names, dtypes)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcolumn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.data_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_platform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_1d_object_array_from_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# The caller is responsible for ensuring that we have np.ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mconstruct_1d_object_array_from_listlike\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1988\u001b[0m     \u001b[0;31m# making a 1D array that contains list-likes is a bit tricky:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1990\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1991\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "UTXOresult1 = UTXOprogram1(start, end)\n",
        "newaddress = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultUTXO1' +str(end)+ '.csv'\n",
        "UTXOresult1.to_csv(newaddress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87VuF3MLMjBG"
      },
      "outputs": [],
      "source": [
        "UTXOresult2 = UTXOprogram2(start, end)\n",
        "newaddress = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultUTXO2' +str(end)+ '.csv'\n",
        "UTXOresult2.to_csv(newaddress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl2kAAeUMj2E"
      },
      "outputs": [],
      "source": [
        "UTXOresult3 = UTXOprogram3(start, end)\n",
        "newaddress = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultUTXO3' +str(end)+ '.csv'\n",
        "UTXOresult3.to_csv(newaddress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za4D16fttiLJ"
      },
      "outputs": [],
      "source": [
        "newaddress1 = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultUTXO1' +str(end)+ '.csv'\n",
        "newaddress2 = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultUTXO2' +str(end)+ '.csv'\n",
        "newaddress3 = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultUTXO3' +str(end)+ '.csv'\n",
        "\n",
        "UTXOresult1 = pd.read_csv(newaddress1).drop(['Unnamed: 0', 'date'], axis = 1)\n",
        "UTXOresult2 = pd.read_csv(newaddress2).drop(['Unnamed: 0', 'date'], axis = 1)\n",
        "UTXOresult3 = pd.read_csv(newaddress3).drop(['Unnamed: 0', 'date'], axis = 1)\n",
        "\n",
        "UTXOresult = UTXOresult1 + UTXOresult2 + UTXOresult3\n",
        "\n",
        "oldaddress = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultUTXO' +str(last_update)+ '.csv'\n",
        "oldUTXOresult = pd.read_csv(oldaddress)\n",
        "oldUTXOresult = oldUTXOresult.drop(['Unnamed: 0'], axis = 1)\n",
        "\n",
        "duration=pd.date_range(start=start, end=end)\n",
        "days = np.size(duration)\n",
        "UTXOresult['date'] = duration\n",
        "UTXOresult = UTXOresult[['date', '-9', '-7', '-5', '-3', '-1', '1', '3', '5', '7', '9', '11']]\n",
        "newUTXOresult = oldUTXOresult.append(UTXOresult)\n",
        "newUTXOresult = newUTXOresult.reset_index(drop = True)\n",
        "duration=pd.date_range(start= end-timedelta(days=len(newUTXOresult)-1), end=end)\n",
        "newUTXOresult['date'] = duration\n",
        "newaddress = '/content/drive/My Drive/UTXO/' + currency + \"/\" + currency + 'ResultUTXO' +str(end)+ '.csv'\n",
        "newUTXOresult.to_csv(newaddress)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "A5BBxnuqVx03",
        "5bVwfAJHaEfx",
        "hog7UNQX3TEM",
        "G4qrxW8Y5p9v",
        "-_r0juK9_FcR"
      ],
      "machine_shape": "hm",
      "name": "Altcoin UTXO Automatic Updater.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}